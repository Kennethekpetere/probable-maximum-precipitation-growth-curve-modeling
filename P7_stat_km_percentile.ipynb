{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244863d-86e5-4b43-8078-f8074e1f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## KENNETH EKPETERE #################################\n",
    "################################# KM PERCENTILE STATS ###############################\n",
    "##################################### (C) 2024  ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353556f1-620f-4190-9fc8-d86a1b834192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import statistics\n",
    "from math import exp\n",
    "from scipy.stats import tmean, tstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a506a9-2c06-4fed-9aea-7ffa465b005f",
   "metadata": {},
   "source": [
    "##### **KM STATS (From Annual Max)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55afcf29-c803-423e-a332-c84c17333a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency factor percentile computation complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Compute percentiles of Frequency Factor Across Durations\n",
    "def compute_FreqFact_percentile(max_file, freq_percentile_file):\n",
    "    # Step 1: Compute frequency factors for each unique ID\n",
    "    # Read input data\n",
    "    data = pd.read_csv(max_file, float_precision='round_trip')\n",
    "\n",
    "    # Subset columns to process\n",
    "    subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "    # Filter rows for years between 2001 and 2022 (inclusive)\n",
    "    data_filtered = data[(data['year'] >= 2001) & (data['year'] <= 2022)]  # station\n",
    "#     data_filtered = data[(data['year'] >= 2000) & (data['year'] <= 2024)]  # IMERG\n",
    "\n",
    "    # Group data by unique ID\n",
    "    grouped = data_filtered.groupby('ID')\n",
    "\n",
    "    # Initialize empty list to hold DataFrame chunks\n",
    "    output_chunks = []\n",
    "\n",
    "    # Loop through each group\n",
    "    for name, group in grouped:\n",
    "        # Compute maximum value for each column\n",
    "        max_pre = group[subset_columns].max()\n",
    "        \n",
    "        # Compute trimmed mean for each column\n",
    "        trimmed_mean = group[subset_columns].apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "\n",
    "        # Compute trimmed standard deviation for each column\n",
    "        trimmed_std = group[subset_columns].apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "\n",
    "        # Compute frequency factor for each column\n",
    "        freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "\n",
    "        # Create DataFrame chunk for this group\n",
    "        output_chunk = pd.DataFrame({\n",
    "            'ID': name,\n",
    "            '30-min': freqfact['30-min'],\n",
    "            '1-hour': freqfact['1-hour'],\n",
    "            '2-hour': freqfact['2-hour'],\n",
    "            '3-hour': freqfact['3-hour'],\n",
    "            '6-hour': freqfact['6-hour'],\n",
    "            '12-hour': freqfact['12-hour'],\n",
    "            '24-hour': freqfact['24-hour'],\n",
    "            '48-hour': freqfact['48-hour'],\n",
    "            '72-hour': freqfact['72-hour']\n",
    "        }, index=[0])\n",
    "\n",
    "        # Append chunk to list\n",
    "        output_chunks.append(output_chunk)\n",
    "\n",
    "    # Concatenate all chunks into final DataFrame\n",
    "    freqfact_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "    # Step 2: Calculate percentiles for frequency factors\n",
    "    # Extract columns with frequency factors\n",
    "    freqfact_values = freqfact_data[subset_columns]\n",
    "\n",
    "    # Define percentile values to compute\n",
    "    percentiles = [0, 2.5, 25, 50, 75, 97.5, 99, 99.5, 99.8, 100]\n",
    "\n",
    "    # Compute percentiles for each duration\n",
    "    percentile_data = pd.DataFrame({\n",
    "        'km_percentile': percentiles\n",
    "    })\n",
    "\n",
    "    for column in subset_columns:\n",
    "        percentile_data[column] = [np.percentile(freqfact_values[column].dropna(), p) for p in percentiles]\n",
    "\n",
    "    # Step 3: Calculate mean and standard deviation for each duration\n",
    "    mean_row = pd.DataFrame({\n",
    "        'km_percentile': ['mean'],\n",
    "        **{column: [freqfact_values[column].mean()] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    stdev_row = pd.DataFrame({\n",
    "        'km_percentile': ['stdev'],\n",
    "        **{column: [freqfact_values[column].std(ddof=1)] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    # Append mean and stdev rows to percentile data\n",
    "    percentile_data = pd.concat([percentile_data, mean_row, stdev_row], ignore_index=True)\n",
    "\n",
    "    # Step 4: Write the output CSV file\n",
    "    percentile_data.to_csv(freq_percentile_file, index=False)\n",
    "\n",
    "    print(\"Frequency factor percentile computation complete\")\n",
    "\n",
    "# # station Annual Maximums\n",
    "# input_file = \"annual_max_stn.csv\"\n",
    "# output_file = \"km_percentile_annual_max_stn.csv\"\n",
    "\n",
    "# IMERG Annual Maximums\n",
    "input_file = \"annual_max.csv\"\n",
    "output_file = \"km_percentile_annual_max.csv\"\n",
    "\n",
    "compute_FreqFact_percentile(input_file, output_file)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33188d7a-5af9-4c0d-aada-4112b47e9d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24fe7487-7ca4-4ea8-99b2-2d7bbe7067c5",
   "metadata": {},
   "source": [
    "##### **KM STATS (Alltime Max and Partial Duration Max)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d18195-6e20-4c4d-9a13-bace86ebf718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency factor percentile computation complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate frequency factor percentiles from alltime maximums\n",
    "def compute_FreqFact_percentile(max_file, freq_percentile_file):\n",
    "    # Step 1: Compute frequency factors for each unique ID\n",
    "    # Read input data\n",
    "    data = pd.read_csv(max_file, float_precision='round_trip')\n",
    "\n",
    "    # Subset columns to process\n",
    "    subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "    # Group data by unique ID\n",
    "    grouped = data.groupby('ID')\n",
    "\n",
    "    # Initialize empty list to hold DataFrame chunks\n",
    "    output_chunks = []\n",
    "\n",
    "    # Loop through each group\n",
    "    for name, group in grouped:\n",
    "        \n",
    "        # For each column, get top 22 sorted values\n",
    "        top_n = group[subset_columns].apply(lambda col: col.sort_values(ascending=False).head(22).reset_index(drop=True))\n",
    "\n",
    "        # Compute max, mean, std, trimmed mean and std on the top 22 values\n",
    "        max_pre = top_n.max()\n",
    "        trimmed_mean = top_n.apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "        trimmed_std = top_n.apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "\n",
    "        # Compute frequency factor for each column\n",
    "        freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "\n",
    "        # Create DataFrame chunk for this group\n",
    "        output_chunk = pd.DataFrame({\n",
    "            'ID': name,\n",
    "            '30-min': freqfact['30-min'],\n",
    "            '1-hour': freqfact['1-hour'],\n",
    "            '2-hour': freqfact['2-hour'],\n",
    "            '3-hour': freqfact['3-hour'],\n",
    "            '6-hour': freqfact['6-hour'],\n",
    "            '12-hour': freqfact['12-hour'],\n",
    "            '24-hour': freqfact['24-hour'],\n",
    "            '48-hour': freqfact['48-hour'],\n",
    "            '72-hour': freqfact['72-hour']\n",
    "        }, index=[0])\n",
    "\n",
    "        # Append chunk to list\n",
    "        output_chunks.append(output_chunk)\n",
    "\n",
    "    # Concatenate all chunks into final DataFrame\n",
    "    freqfact_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "    # Step 2: Calculate percentiles for frequency factors\n",
    "    # Extract columns with frequency factors\n",
    "    freqfact_values = freqfact_data[subset_columns]\n",
    "\n",
    "    # Define percentile values to compute\n",
    "    percentiles = [0, 2.5, 25, 50, 75, 97.5, 99, 99.5, 99.8, 100]\n",
    "\n",
    "    # Compute percentiles for each duration\n",
    "    percentile_data = pd.DataFrame({\n",
    "        'km_percentile': percentiles\n",
    "    })\n",
    "\n",
    "    for column in subset_columns:\n",
    "        percentile_data[column] = [np.percentile(freqfact_values[column].dropna(), p) for p in percentiles]\n",
    "\n",
    "    # Step 3: Calculate mean and standard deviation for each duration\n",
    "    mean_row = pd.DataFrame({\n",
    "        'km_percentile': ['mean'],\n",
    "        **{column: [freqfact_values[column].mean()] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    stdev_row = pd.DataFrame({\n",
    "        'km_percentile': ['stdev'],\n",
    "        **{column: [freqfact_values[column].std(ddof=1)] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    # Append mean and stdev rows to percentile data\n",
    "    percentile_data = pd.concat([percentile_data, mean_row, stdev_row], ignore_index=True)\n",
    "\n",
    "    # Step 4: Write the output CSV file\n",
    "    percentile_data.to_csv(freq_percentile_file, index=False)\n",
    "\n",
    "    print(\"Frequency factor percentile computation complete\")\n",
    "\n",
    "\n",
    "# # Alltime Maximums\n",
    "# input_file = \"alltime_max.csv\"\n",
    "# output_file = \"km_percentile_alltime_max.csv\"\n",
    "\n",
    "\n",
    "# Alltime Partial Duration Maximums\n",
    "input_file = \"alltime_partial_duration_max.csv\"\n",
    "output_file = \"km_percentile_alltime_partial_duration_max.csv\"\n",
    "\n",
    "compute_FreqFact_percentile(input_file, output_file)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8251e27-f908-4637-b7c2-518385021973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ab54b-fcab-4cc0-a991-6f7ec4dc7ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89f287-26fb-42ca-a8f3-cedad1c66737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f38ff9-97be-40f8-948f-325ff059fce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2a44a-9b98-4606-8adc-6a22b82445d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5998426-5595-4124-887c-ea1f72aba5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758a98f-36de-4cc6-92ca-88419fb1fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584de6ca-4411-4728-a4be-12e3af0ccb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a77111-95cb-4180-bf51-b4d11dd049df",
   "metadata": {},
   "source": [
    "##### **Extras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce78117-cd0f-493e-9ada-0266f7b498b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate frequency factor percentiles from alltime maximums\n",
    "def compute_FreqFact_percentile(max_file, freq_percentile_file):\n",
    "    # Step 1: Compute frequency factors for each unique ID\n",
    "    # Read input data\n",
    "    data = pd.read_csv(max_file, float_precision='round_trip')\n",
    "\n",
    "    # Subset columns to process\n",
    "    subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "    # Group data by unique ID\n",
    "    grouped = data.groupby('ID')\n",
    "\n",
    "    # Initialize empty list to hold DataFrame chunks\n",
    "    output_chunks = []\n",
    "\n",
    "    # Loop through each group\n",
    "    for name, group in grouped:\n",
    "        # Compute maximum value for each column\n",
    "        max_pre = group[subset_columns].max()\n",
    "        \n",
    "        # Compute trimmed mean for each column\n",
    "        trimmed_mean = group[subset_columns].apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "\n",
    "        # Compute trimmed standard deviation for each column\n",
    "        trimmed_std = group[subset_columns].apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "\n",
    "        # Compute frequency factor for each column\n",
    "        freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "\n",
    "        # Create DataFrame chunk for this group\n",
    "        output_chunk = pd.DataFrame({\n",
    "            'ID': name,\n",
    "            '30-min': freqfact['30-min'],\n",
    "            '1-hour': freqfact['1-hour'],\n",
    "            '2-hour': freqfact['2-hour'],\n",
    "            '3-hour': freqfact['3-hour'],\n",
    "            '6-hour': freqfact['6-hour'],\n",
    "            '12-hour': freqfact['12-hour'],\n",
    "            '24-hour': freqfact['24-hour'],\n",
    "            '48-hour': freqfact['48-hour'],\n",
    "            '72-hour': freqfact['72-hour']\n",
    "        }, index=[0])\n",
    "\n",
    "        # Append chunk to list\n",
    "        output_chunks.append(output_chunk)\n",
    "\n",
    "    # Concatenate all chunks into final DataFrame\n",
    "    freqfact_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "    # Step 2: Calculate percentiles for frequency factors\n",
    "    # Extract columns with frequency factors\n",
    "    freqfact_values = freqfact_data[subset_columns]\n",
    "\n",
    "    # Define percentile values to compute\n",
    "    percentiles = [0, 2.5, 25, 50, 75, 97.5, 99, 99.5, 99.8, 100]\n",
    "\n",
    "    # Compute percentiles for each duration\n",
    "    percentile_data = pd.DataFrame({\n",
    "        'km_percentile': percentiles\n",
    "    })\n",
    "\n",
    "    for column in subset_columns:\n",
    "        percentile_data[column] = [np.percentile(freqfact_values[column].dropna(), p) for p in percentiles]\n",
    "\n",
    "    # Step 3: Calculate mean and standard deviation for each duration\n",
    "    mean_row = pd.DataFrame({\n",
    "        'km_percentile': ['mean'],\n",
    "        **{column: [freqfact_values[column].mean()] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    stdev_row = pd.DataFrame({\n",
    "        'km_percentile': ['stdev'],\n",
    "        **{column: [freqfact_values[column].std(ddof=1)] for column in subset_columns}\n",
    "    })\n",
    "\n",
    "    # Append mean and stdev rows to percentile data\n",
    "    percentile_data = pd.concat([percentile_data, mean_row, stdev_row], ignore_index=True)\n",
    "\n",
    "    # Step 4: Write the output CSV file\n",
    "    percentile_data.to_csv(freq_percentile_file, index=False)\n",
    "\n",
    "    print(\"Frequency factor percentile computation complete\")\n",
    "\n",
    "# Alltime Maximums\n",
    "input_file = \"alltime_max.csv\"\n",
    "output_file = \"km_percentile_alltime_max.csv\"\n",
    "\n",
    "compute_FreqFact_percentile(input_file, output_file)\n",
    "print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
