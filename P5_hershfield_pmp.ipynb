{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244863d-86e5-4b43-8078-f8074e1f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## KENNETH EKPETERE #################################\n",
    "################################# PMP IMPLEMENTATION ###############################\n",
    "##################################### (C) 2024  ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353556f1-620f-4190-9fc8-d86a1b834192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import statistics\n",
    "from math import exp\n",
    "from scipy.stats import tmean, tstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a506a9-2c06-4fed-9aea-7ffa465b005f",
   "metadata": {},
   "source": [
    "##### **HERSHFIELD PMP (Station and IMERG AMS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffe9015-cd7d-4538-bc9c-da630093cc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hershfield PMP computation complete\n"
     ]
    }
   ],
   "source": [
    "# Annual Maximums to PMP Computation\n",
    "input_file = \"annual_max.csv\"\n",
    "output_file = \"annual_max_pmp.csv\"\n",
    "\n",
    "# Read input data\n",
    "data = pd.read_csv(input_file, float_precision='round_trip')\n",
    "\n",
    "# Subset columns to process\n",
    "subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "# Filter rows for years between 2000 and 2024 (inclusive)\n",
    "data_filtered = data[(data['year'] >= 2000) & (data['year'] <= 2024)]\n",
    "\n",
    "# Group data by unique ID\n",
    "grouped = data_filtered.groupby('ID')\n",
    "\n",
    "# Initialize empty list to hold DataFrame chunks\n",
    "output_chunks = []\n",
    "\n",
    "# Loop through each group\n",
    "for name, group in grouped:\n",
    "    # Compute maximum value for each column\n",
    "    max_pre = group[subset_columns].max()\n",
    "    \n",
    "    # Compute mean for each column\n",
    "    mean_pre = group[subset_columns].mean()\n",
    "    \n",
    "    # Compute standard deviation for each column\n",
    "    std_pre = group[subset_columns].std()\n",
    "    \n",
    "    # Compute trimmed mean for each column\n",
    "    trimmed_mean = group[subset_columns].apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "    \n",
    "    # Compute trimmed standard deviation for each column\n",
    "    trimmed_std = group[subset_columns].apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "    \n",
    "    # Compute frequency factor for each column\n",
    "    freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "    \n",
    "    # Compute HPMP for each column\n",
    "    HPMP = mean_pre + (freqfact * std_pre)\n",
    "    \n",
    "    # Create DataFrame chunk for this group\n",
    "    output_chunk = pd.DataFrame({\n",
    "        'ID': name,\n",
    "        '30-min': HPMP['30-min'],\n",
    "        '1-hour': HPMP['1-hour'],\n",
    "        '2-hour': HPMP['2-hour'],\n",
    "        '3-hour': HPMP['3-hour'],\n",
    "        '6-hour': HPMP['6-hour'],\n",
    "        '12-hour': HPMP['12-hour'],\n",
    "        '24-hour': HPMP['24-hour'],\n",
    "        '48-hour': HPMP['48-hour'],\n",
    "        '72-hour': HPMP['72-hour']\n",
    "    }, index=[0])  # Ensure each chunk has only one row\n",
    "    \n",
    "    # Append chunk to list\n",
    "    output_chunks.append(output_chunk)\n",
    "\n",
    "# Concatenate all chunks into final DataFrame\n",
    "output_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_data.to_csv(output_file, index=False)\n",
    "print(\"Hershfield PMP computation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79633819-5ad6-4342-a92c-db7f712446dd",
   "metadata": {},
   "source": [
    "##### **HERSHFIELD PMP (IMERG All-time Maximums)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54eecc6a-efc4-4411-ac03-5b20cac94f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hershfield Alltime PMP computation complete\n"
     ]
    }
   ],
   "source": [
    "# Alltime Maximums to PMP Computation\n",
    "input_file = \"alltime_max.csv\"\n",
    "output_file = \"alltime_max_pmp.csv\"\n",
    "\n",
    "# Read input data\n",
    "data = pd.read_csv(input_file, float_precision='round_trip')\n",
    "\n",
    "# Subset columns to process\n",
    "subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "# Group data by unique ID\n",
    "grouped = data.groupby('ID')\n",
    "\n",
    "# Initialize empty list to hold DataFrame chunks\n",
    "output_chunks = []\n",
    "\n",
    "# Loop through each group\n",
    "for name, group in grouped:\n",
    "    # Compute maximum value for each column\n",
    "    max_pre = group[subset_columns].max()\n",
    "    \n",
    "    # Compute mean for each column\n",
    "    mean_pre = group[subset_columns].mean()\n",
    "    \n",
    "    # Compute standard deviation for each column\n",
    "    std_pre = group[subset_columns].std()\n",
    "    \n",
    "    # Compute trimmed mean for each column\n",
    "    trimmed_mean = group[subset_columns].apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "    \n",
    "    # Compute trimmed standard deviation for each column\n",
    "    trimmed_std = group[subset_columns].apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "    \n",
    "    # Compute frequency factor for each column\n",
    "    freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "    \n",
    "    # Compute HPMP for each column\n",
    "    HPMP = mean_pre + (freqfact * std_pre)\n",
    "    \n",
    "    # Create DataFrame chunk for this group\n",
    "    output_chunk = pd.DataFrame({\n",
    "        'ID': name,\n",
    "        '30-min': HPMP['30-min'],\n",
    "        '1-hour': HPMP['1-hour'],\n",
    "        '2-hour': HPMP['2-hour'],\n",
    "        '3-hour': HPMP['3-hour'],\n",
    "        '6-hour': HPMP['6-hour'],\n",
    "        '12-hour': HPMP['12-hour'],\n",
    "        '24-hour': HPMP['24-hour'],\n",
    "        '48-hour': HPMP['48-hour'],\n",
    "        '72-hour': HPMP['72-hour']\n",
    "    }, index=[0])  # Ensure each chunk has only one row\n",
    "    \n",
    "    # Append chunk to list\n",
    "    output_chunks.append(output_chunk)\n",
    "\n",
    "# Concatenate all chunks into final DataFrame\n",
    "output_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_data.to_csv(output_file, index=False)\n",
    "print(\"Hershfield Alltime PMP computation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b90836-d588-4d55-b4a4-66132cde9d02",
   "metadata": {},
   "source": [
    "##### **HERSHFIELD PMP (IMERG's Partial Duration Maximums)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492edee1-55a4-4646-9285-ebc89a624da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hershfield Partial Duration PMP computation complete\n"
     ]
    }
   ],
   "source": [
    "# Alltime Maximums to PMP Computation\n",
    "input_file = \"alltime_partial_duration_max.csv\"\n",
    "output_file = \"alltime_partial_duration_max_pmp.csv\"\n",
    "\n",
    "# Read input data\n",
    "data = pd.read_csv(input_file, float_precision='round_trip')\n",
    "\n",
    "# Subset columns to process\n",
    "subset_columns = ['30-min', '1-hour', '2-hour', '3-hour', '6-hour', '12-hour', '24-hour', '48-hour', '72-hour']\n",
    "\n",
    "# Group data by unique ID\n",
    "grouped = data.groupby('ID')\n",
    "\n",
    "# Initialize empty list to hold DataFrame chunks\n",
    "output_chunks = []\n",
    "\n",
    "# Loop through each group\n",
    "for name, group in grouped:\n",
    "    # Compute maximum value for each column\n",
    "    max_pre = group[subset_columns].max()\n",
    "    \n",
    "    # Compute mean for each column\n",
    "    mean_pre = group[subset_columns].mean()\n",
    "    \n",
    "    # Compute standard deviation for each column\n",
    "    std_pre = group[subset_columns].std()\n",
    "    \n",
    "    # Compute trimmed mean for each column\n",
    "    trimmed_mean = group[subset_columns].apply(lambda x: np.mean(np.sort(x)[:-1]))\n",
    "    \n",
    "    # Compute trimmed standard deviation for each column\n",
    "    trimmed_std = group[subset_columns].apply(lambda x: np.std(np.sort(x)[:-1], ddof=1))\n",
    "    \n",
    "    # Compute frequency factor for each column\n",
    "    freqfact = ((max_pre - trimmed_mean) / trimmed_std)\n",
    "    \n",
    "    # Compute HPMP for each column\n",
    "    HPMP = mean_pre + (freqfact * std_pre)\n",
    "    \n",
    "    # Create DataFrame chunk for this group\n",
    "    output_chunk = pd.DataFrame({\n",
    "        'ID': name,\n",
    "        '30-min': HPMP['30-min'],\n",
    "        '1-hour': HPMP['1-hour'],\n",
    "        '2-hour': HPMP['2-hour'],\n",
    "        '3-hour': HPMP['3-hour'],\n",
    "        '6-hour': HPMP['6-hour'],\n",
    "        '12-hour': HPMP['12-hour'],\n",
    "        '24-hour': HPMP['24-hour'],\n",
    "        '48-hour': HPMP['48-hour'],\n",
    "        '72-hour': HPMP['72-hour']\n",
    "    }, index=[0])  # Ensure each chunk has only one row\n",
    "    \n",
    "    # Append chunk to list\n",
    "    output_chunks.append(output_chunk)\n",
    "\n",
    "# Concatenate all chunks into final DataFrame\n",
    "output_data = pd.concat(output_chunks, ignore_index=True)\n",
    "\n",
    "# Write output DataFrame to CSV\n",
    "output_data.to_csv(output_file, index=False)\n",
    "print(\"Hershfield Partial Duration PMP computation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2769b-d0d8-4943-819d-1ee8bf71b7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e01ea-4b6e-4a35-ba2b-2a6ace0f47b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741d52d-8387-4b52-8026-2159169384f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f81395-754b-4971-bf0c-e4590c709880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ac363-d347-46b7-91e8-9de48716e8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
